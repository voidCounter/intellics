
%********************************** %First Section  **************************************
\section{Background} 
Education has transformed from conventional teacher-led methods to more engaging and learner-focused strategies. Traditional instructional techniques frequently adopt a one-size-fits-all approach. Hence they find it challenging to meet each student's unique learning requirements. These techniques can result in a lack of interest and low learning results, as they fail to adapt different speeds, existing knowledge, or individual learning preferences \citep{raneEducation40502024}.

The fundamental changes Artificial Intelligence(AI) brings to education are changes in traditional teaching methods. It has introduced personalized learning experiences according to individual learners’ unique needs and preferences. This change in the educational structure boosts student participation and improves learning results \citep{oyebolaolusolaayeniAIEducationReview2024}.

One significant application of AI in education is Intelligent Tutoring Systems (ITS), which aims to deliver personalised instruction that mimics the role of human tutors. These systems adaptively modify learning paths, suggest relevant content to students like a real human tutor. They also involve students in conversations, which enhance the educational experience to be more interactive and customised to each learner’s learning requirements \citep{mousavinasabIntelligentTutoringSystems2021}.

Though intelligent tutoring system has the potential to enhance learning, the widespread adoption of Intelligent Tutoring Systems (ITS) remains limited. Developing and maintaining ITS can be costly and often requires specialised teams. It makes large-scale deployment challenging \citep{alkhatlanIntelligentTutoringSystems2018}. There are not so many Open-source platforms, which hinders replication and more general adoption \citep{pardosOATutorOpensourceAdaptive2023}. Moreover, much of the research and implementation of ITS has been concentrated in developed countries. As a result, there is a significant gap in evaluation and use in other contexts \cite{mousavinasabIntelligentTutoringSystems2021}. These practical and contextual barriers have slowed the integration of ITS into everyday educational settings.

To address these gaps, this project, IntelliCS, builds a web-based Intelligent Tutoring System for Object-Oriented Programming (OOP). It offers a personalised and interactive learning experience by recommending lessons and questions based on each student’s needs. A robust logging system records a wide range of student interactions. This data powers the adaptive engine and allows A/B testing. Educators can test strategies and find what works best. A dedicated admin module lets teachers monitor progress and manage content. Together, these features support effective learning and teaching.

\section{Problem Statement}
Teaching Object-Oriented Programming (OOP) is challenging. Its core concepts, like inheritance and polymorphism, are abstract and often need tailored instruction for students to grasp them \citep{mousavinasabIntelligentTutoringSystems2021}. Traditional teaching methods usually apply a one-size-fits-all approach. This can cause students to lose interest and struggle to master the material.

Intelligent Tutoring Systems (ITSs) show promise in offering personalized, adaptive learning. Yet, their widespread use faces significant barriers. They are often costly and complicated to build. Few open-source options exist for researchers and educators \citep{alkhatlanIntelligentTutoringSystems2018, pardosOATutorOpensourceAdaptive2023}.

Many existing ITSs rely on simplified learning models. They track basic information, such as whether an answer is correct, but overlook richer insights from student interactions. This limited data makes it hard to understand how students learn complex topics like OOP. It also prevents educators and researchers from testing different strategies effectively \citep{saric-grgicTwentyfiveYearsBayesian2024}.

These challenges show a clear need for a new ITS. The system should be accessible, personalised, and designed to capture rich, detailed data. Such a system would support rigorous research and experimentation, advancing the field of adaptive learning.


\section{Research Challenges}
Developing an effective intelligent tutoring system for Object-Oriented Programming faces several key challenges. These challenges include:
\begin{itemize}
\item \textbf{Modeling Multi-Skill Knowledge in OOP:} Traditional knowledge tracing models, like Bayesian Knowledge Tracing (BKT), struggle with OOP’s complex, interconnected concepts. They often assume each skill is independent and represent mastery as a simple binary state, either a student knows it or they don’t \citep{corbettKnowledgeTracingModeling1995a}. This approach makes it hard to track learning accurately for concepts that depend on one another, such as classes and polymorphism.

\item \textbf{Building a Robust and Personalised Recommendation Engine:} A key challenge in adaptive learning is delivering content that is both relevant and appropriately difficult. This problem is especially acute when a student first joins, known as the \textit{cold-start problem} \citep{choSystematicReviewKnowledgea}, where limited data makes recommendation difficult. The main task is to design a recommendation engine that can handle this initial sparsity. It must use all available data, including student behaviour and mastery estimates, to provide personalised lessons and question recommendations continuously \citep{murtazaAIBasedPersonalizedELearning2022}.

\item \textbf{Ensuring a Usable and Engaging User Experience (UI/UX):} An effective intelligent tutoring system requires an interface that is intuitive, engaging, and easy to navigate. A poor user experience can frustrate students, reduce engagement, and even cause them to abandon the system, regardless of how advanced the adaptive engine is. The challenge is to design a UI that integrates complex adaptive features while maintaining a simple, motivating, and positive learning environment \citep{Anderson1995CognitiveTL}.

\item \textbf{Correctness and Fidelity of Logged Data:} An intelligent tutoring system depends on accurate and complete user interaction data \citep{murtazaAIBasedPersonalizedELearning2022}. Ensuring this fidelity is a major challenge. System or network issues can cause dropped events, wrong timestamps, or out-of-order logs. Such errors compromise the data used for knowledge tracing and model training, reducing system effectiveness \citep{abdelrahmanKnowledgeTracingSurvey2023a}. The challenge is to implement a reliable logging mechanism that preserves the accuracy and integrity of every data point.

\item \textbf{Supporting Experimental Designs:} Most existing systems are not designed for flexible experimentation, which limits researchers and teachers from conducting controlled studies on different learning strategies \citep{pardosOATutorOpensourceAdaptive2023}. The challenge is to build a system that enables A/B testing and other experimental designs. It should allow systematic comparison of teaching methods to identify which strategies are most effective. For instance, the system can compare question-only paths, question + hints paths, or question + hints + scaffolds paths to evaluate their impact on learning outcomes.

\item \textbf{Validating Learning Outcomes and System Effectiveness:} A final challenge is demonstrating that the system actually improves learning. Building the system alone is not enough. The challenge is to define and apply metrics that measure both student engagement and learning gains. This requires careful data collection and analysis to support controlled experiments, providing clear evidence of the system’s effectiveness.
\end{itemize}

\section{Research Questions}

To address the challenges outlined in developing an effective intelligent tutoring system for Object-Oriented Programming (OOP), the following research questions are proposed. These questions aim to guide the investigation into creating a robust, adaptive, and effective learning environment.

\textbf{Main Research Question (MRQ):}  
How well can IntelliCS enhance learning in Object-Oriented Programming through a personalized, adaptive, and engaging learning experience? \\

\textbf{Sub-Research Questions (SRQs):}  
\begin{enumerate}
    \item How can knowledge tracing models be enhanced to account for the interdependent nature of OOP concepts, such as classes and polymorphism, moving beyond the binary assumptions of traditional Bayesian Knowledge Tracing (BKT)? \citep{corbettKnowledgeTracingModeling1995a}
    \item What strategies can be developed to address the cold-start problem in recommendation engines, ensuring accurate and personalized lesson and question recommendations for new users with limited interaction data?
    \item How can an intuitive and engaging user interface be designed to integrate complex adaptive features while maintaining simplicity and fostering student motivation in an OOP tutoring system?
    \item What mechanisms can be implemented to ensure the accuracy and reliability of logged user interaction data, mitigating issues such as dropped events, incorrect timestamps, or out-of-order logs, to support effective knowledge tracing and model training?
    \item How can an intelligent tutoring system be architected to natively support flexible experimental designs, such as A/B testing, to enable systematic evaluation of different instructional strategies for OOP learning?
    \item What metrics and evaluation methods can be used to rigorously assess student engagement and learning outcomes in an OOP intelligent tutoring system, providing evidence of its effectiveness through controlled experiments?
\end{enumerate}
% \section{Thesis Organization}
% It is a long established fact that a reader will be distracted by the readable content of a page when looking at its layout.
                                  
% IntelliCS related work
\chapter{Related Work}
\section{Intelligent Tutoring Systems}
In Intelligent Tutoring Systems, different Artificial Intelligence techniques are used to create a program that imitates a real human tutor. The tutor knows the topic or subject it teaches, the student's knowledge regarding the topic, and the approach or method to teach the topic properly \citep{Nwana1990IntelligentTS}.
\citet{Nwana1990IntelligentTS} outlines four general components of an ITS that are still relevant today for most tutoring systems (Figure~\ref{fig:its-components}). 
\begin{figure}[!h]
    \centering
    \includegraphics[width=0.8\linewidth]{Chapter2/Figs/Vector/ITS-components.pdf}
    \caption{General Components of an Intelligent Tutoring System.}
    \label{fig:its-components}
\end{figure}

The expert knowledge module holds the facts and rules of the specific subject to be taught to the student. The student model module stores and processes different characteristics regarding students, namely the level of knowledge, activities, responses, learning styles, behaviors, knowledge deficiency, etc. The tutoring module uses information from the student model module and tutorial goals to decide the learning activities. Lastly, the user interface module works as the bridge between the user and the system.


\begin{table*}[h]
\centering

\caption{AI Paradigms in Education}
\label{tab:ai_paradigms}
\begin{tabular}{p{3cm} p{3cm} p{5cm} p{3cm}} \toprule
    \textbf{Paradigm} & \textbf{Learning Theory} & \textbf{Description} & \textbf{Example} \\ \midrule
    \textbf{AI-Directed (Learner-as-Recipient)} & Behaviorism & AI delivers structured content with fixed learning paths and immediate but rigid feedback. & Cognitive Tutors \\ \midrule
    \textbf{AI-Supported (Learner-as-Collaborator)} & Cognitive and Social Constructivism & AI adjusts content difficulty based on learner performance. Additionally, AI provides hints and interactive support. & Adaptive Learning Systems \\ \midrule
    \textbf{AI-Empowered (Learner-as-Leader)} & Complexity Theory & AI acts as a facilitator. It allows learners to explore concepts independently while providing guidance when needed. & Inquiry-Based AI Tools \\ \bottomrule
\end{tabular}
\end{table*}

\noindent Throughout the years, research on ITS has advanced different techniques and methodologies used in these 4 modules. As a result, ITS has transitioned from rule-based tutoring models to AI-enhanced adaptive learning systems that utilise methods such as Natural Language Processing (NLP) and Knowledge Tracing to improve the personalisation of instructions \citep{batsaikhanEffectsGenerativeArtificial2024, choSystematicReviewKnowledgea}. These innovations could be characterized by the AIED paradigms proposed by \citet{ouyangArtificialIntelligenceEducation2021}: Initially AI-Directed, Learner-as-Recipient, then AI-Supported, Learner-as-Collaborator and finally AI-Empowered, Learner-as-Leader as shown in Table~\ref{tab:ai_paradigms}.

Intelligent Tutoring Systems (ITS) have consistently demonstrated their helpfulness through extensive research and empirical evidence, often achieving significant learning gains. For instance, a meta-analysis by Kulik and Fletcher in 2015 found that 92\% of studies indicated students using ITS outperformed those receiving traditional classroom instruction, with performance improvements showing moderate to strong effect sizes, up to a 0.66 median \citep{alkhatlanIntelligentTutoringSystems2018, mousavinasabIntelligentTutoringSystems2021}. Another meta-analysis by VanLehn in 2011 revealed that step-based computer tutoring (effect size 0.76) was almost as effective as human tutoring (effect size 0.79) when compared to no tutoring, reinforcing ITS as a viable and cost-effective alternative \citep{alkhatlanIntelligentTutoringSystems2018, letourneauSystematicReviewAIdriven2025}. Specific systems like the Lisp Tutor showed that students completed exercises 30\% faster and performed 43\% better on posttest \citep{Anderson1995CognitiveTL}, while Cognitive Tutor Algebra students scored 15–25\% higher on standardised tests and 50–100\% higher on problem-solving tasks compared to traditional courses \citep{Koedinger2007-yl}. These results, among others, underscore the proven effectiveness of ITS in enhancing learning outcomes and efficiency \citep{alkhatlanIntelligentTutoringSystems2018}.

\section{Approaches to Personalisation and Adaptation}
\cite{Carbonell1970AIIC}'s SCHOLAR system was an early intelligent tutoring system with mixed-initiative dialogue for subject review, such as South American geography. It uses a semantic network to store domain knowledge. For assessing student responses, it utilizes sentence templates and keyword matching. Although its student modeling and natural language processing were limited, SCHOLAR laid the groundwork for modern ITS by introducing design principles like the separation of tutorial strategies from domain knowledge.

\subsection{Cognitive Tutors (CT)}

Cognitive Tutors (CTs) are based on the ACT-R cognitive theory, which models human problem solving and skill acquisition. They represent student competence as a set of fine-grained production rules, each encoding a specific cognitive skill \citep{Anderson1993RulesOT}. These rules link problem states to actions, guiding students toward goals and subgoals, such as writing a loop in programming. Using model tracing, CTs compare a student’s actions against the cognitive model to provide immediate, targeted feedback and hints \citep{Anderson1995CognitiveTL}. They also use Bayesian Knowledge Tracing (BKT) to estimate skill mastery. This allows a mastery learning approach, where students practice until they achieve proficiency \citep{corbettKnowledgeTracingModeling1995a}. This dynamic adaptation aligns instruction with individual learning needs and fosters deeper understanding before students move on.

For example, the ACT Programming Tutor (APT) tracks students’ coding steps and provides real-time feedback. It ensures they master a rule, such as setting a loop counter, before progressing to more advanced tasks \citep{Anderson1995CognitiveTL}. The Andes Physics Tutoring System also uses model tracing to guide students through predefined solution paths. However, unlike APT, it follows a fixed sequence and does not dynamically tailor problem selection to a student’s knowledge state \citep{VanLehn2005TheAP}.

\begin{figure}[!h]
\centering
\includegraphics[width=\linewidth]{Chapter2/Figs/Vector/cognitive-tutors.pdf}
\caption{Cognitive Tutors in OOP Practice.}
\label{fig:cognitive-tutors-scenario}
\end{figure}

Figure \ref{fig:cognitive-tutors-scenario} shows how Cognitive Tutors support OOP practice using model tracing and Bayesian Knowledge Tracing (BKT). The system compares a student’s code input step by step against predefined production rules. Immediate hints are provided when errors occur. As students progress, BKT updates their mastery state, which guides adaptive sequencing of practice until proficiency is achieved.

Despite their strengths, Cognitive Tutors have notable limitations. Modeling knowledge as a set of independent skills makes it hard to capture complex, interdependent OOP concepts \citep{choSystematicReviewKnowledgea}. Their design also creates a cold-start problem, as extensive prior data is needed to build a student model. This makes personalising instruction for new users difficult. Additionally, their fixed, rule-based architecture limits flexibility and makes it hard to support experimental designs, such as A/B testing, which are essential for evaluating teaching strategies \citep{pardosOATutorOpensourceAdaptive2023}.

\subsection{Constraint-Based Models (CBM)}

Constraint-Based Models (CBMs) represent knowledge as a set of rules or constraints that a correct solution must meet. They provide a flexible alternative to traditional model tracing \citep{alkhatlanIntelligentTutoringSystems2018}. Unlike Cognitive Tutors, which follow fixed solution paths, CBMs allow students to use different approaches as long as core principles are respected. When a student breaks a constraint, the system identifies the error and gives targeted feedback to guide correction. Many CBMs also use Bayesian belief networks to model student knowledge and infer intentions. This allows the system to adapt instruction within the Zone of Proximal Development, keeping tasks challenging but achievable \citep{Cole1978MindIS}. CBMs are computationally efficient and work well in domains like Object-Oriented Programming, where multiple correct solutions are standard.

For example, the Virtual Physics System (VipS) teaches pulley mechanics through interactive simulations \citep{myneniInteractiveIntelligentLearning2013}. VipS defines valid pulley setups as constraints and lets students experiment freely. When a student violates a rule, such as misapplying force, the system provides multimedia feedback and dynamic hints. By tracking knowledge, VipS adjusts challenges to keep learning engaging and effective.

\begin{figure}[!h]
\centering
\includegraphics[width=\linewidth]{Chapter2/Figs/Vector/CBM.pdf}
\caption{Constraint-based feedback in an OOP exercise.}
\label{fig:constraint-based-models-scenario}
\end{figure}

Figure \ref{fig:constraint-based-models-scenario} shows how CBMs guide OOP practice. The system checks whether a student’s code satisfies domain constraints instead of following a fixed solution path. When a constraint is broken, such as a missing attribute or incorrect method signature, the system provides targeted feedback to help the student correct the error. This approach allows multiple valid solutions while ensuring conceptual accuracy.

However, CBMs have limitations. Because they focus on principles rather than step-by-step solutions, they can offer only limited guidance at the level of individual actions. They also do not model a student’s knowledge in fine detail, making it challenging to give proactive, precise feedback for complex programming tasks. CBMs are largely reactive, responding after an error occurs, rather than anticipating misconceptions. This limits their ability to deliver truly dynamic and personalised support \citep{alkhatlanIntelligentTutoringSystems2018}.

\subsection{Curriculum Sequencing / Adaptive Hypermedia}

Curriculum Sequencing shapes the learning journey by choosing activities that fit a student’s current abilities. It tracks progress through a student model, often using knowledge tracing to estimate how well someone grasps specific skills. Rather than guiding every step, the system picks the next problem or lesson to keep students moving forward, aligning with the curriculum’s structure \citep{alkhatlanIntelligentTutoringSystems2018}. It aims to present tasks that strike a balance—challenging enough to spark growth but not so hard they discourage effort—often using techniques like Bayesian inference to gauge when a student is ready for more \citep{corbettKnowledgeTracingModeling1995a}.

\begin{figure}[!h]
    \centering
    \includegraphics[width=\linewidth]{Chapter2/Figs/Vector/curriculum-sequencing.pdf}
    \caption{Curriculum sequencing in OOP practice.}
    \label{fig:curriculum-sequencing-scenario}
\end{figure}

Figure \ref{fig:curriculum-sequencing-scenario} illustrates how curriculum sequencing adapts the learning path in OOP practice. The sequencer selects the next exercise based on the student’s mastery level, as estimated by the student model. This feedback loop ensures that learners progress through OOP concepts (e.g., classes, inheritance, polymorphism) at an appropriate pace.


ELM-ART (ELM Adaptive Remote Tutor) is a web-based ITS designed to teach Lisp programming. It guides students through course materials by checking whether they have the necessary prerequisite knowledge. The system dynamically highlights and sorts relevant links to help students follow the right learning path. If a student tries to access material without the required knowledge, ELM-ART alerts them and suggests links to relevant textbook pages. This ensures a guided and personalized learning experience \citep{alkhatlanIntelligentTutoringSystems2018}.

OATutor (Open Adaptive Tutor) is an open-source system built for educational research. It structures lessons hierarchically, linking each one to specific learning skills. The system uses Bayesian Knowledge Tracing (BKT) to estimate mastery of each skill. Based on these estimates, OATutor selects the next problem and adjusts practice to prevent under- or over-practice. This design makes it a valuable tool for researchers studying adaptive learning principles \citep{pardosOATutorOpensourceAdaptive2023}.
\section{The Challenge of Student Modeling}

\textbf{Knowledge Tracing (KT)} is a central part of the student model in Intelligent Tutoring Systems (ITS). Its purpose is to estimate a student’s evolving knowledge state and mastery of specific skills, or “knowledge components” (KCs), based on their learning interactions \citep{abdelrahmanKnowledgeTracingSurvey2023a, choSystematicReviewKnowledgea}. KT enables adaptive instruction and personalised learning experiences \citep{abdelrahmanKnowledgeTracingSurvey2023a, murtazaAIBasedPersonalizedELearning2022}.

KCs are typically defined as atomic skills or concepts required for problem-solving. For example, in Object-Oriented Programming (OOP), one KC could be defining a class correctly, another could be implementing a method, and a third could be applying inheritance to create a subclass. Each of these skills is distinct and measurable, allowing the ITS to track and assess student learning at a fine-grained level \citep{corbettKnowledgeTracingModeling1995a}.

\begin{figure}[!h]
\centering
\includegraphics[width=\linewidth]{Chapter2/Figs/Vector/Knowledge-tracing.pdf}
\caption{An example scenario of knowledge tracing in an Intelligent Tutoring System (ITS).}
\label{fig:knowledge-tracing-scenario}
\end{figure}

Figure~\ref{fig:knowledge-tracing-scenario} illustrates a KT scenario. The system presents questions (Q1–Q5) and records the student’s answers. Each question is linked to one or more KCs. The dependency graph shows how KCs relate—for example, KC2 depends on KC1. Using student responses and the graph, the ITS updates the student’s knowledge state dynamically. Mastery levels for each KC can be visualized over time, often using radar charts to show progress.

One of the earliest and most widely used KT methods is \textbf{Bayesian Knowledge Tracing (BKT)}, introduced by \citet{corbettKnowledgeTracingModeling1995a} \citep{saric-grgicTwentyfiveYearsBayesian2024, choSystematicReviewKnowledgea, abdelrahmanKnowledgeTracingSurvey2023a}. BKT models student learning as a Hidden Markov Model, estimating the probability that a student knows or does not know a skill. The model uses parameters for learning, forgetting, guessing, and slipping to track knowledge over time \citep{saric-grgicTwentyfiveYearsBayesian2024, yudelsonIndividualizedBayesianKnowledge2013}.

While BKT is interpretable and effective, the “vanilla” model has limitations. It assumes binary knowledge states and treats skills as independent. This makes it difficult to capture interdependent concepts, which are common in domains like OOP \citep{saric-grgicTwentyfiveYearsBayesian2024}. Researchers have addressed these limitations by:
\begin{itemize}
\item \textbf{Modeling Domain Knowledge Properties:} Representing relationships between skills, such as prerequisites or combinations, to better reflect how knowledge is structured.
\item \textbf{Integrating Multiple Attempts and Student Characteristics:} Considering a student’s full range of interactions—including multiple attempts, hints, or response time—rather than only the final answer.
\end{itemize}

Fitting BKT models to data requires estimating parameters from student interactions. The Expectation-Maximisation (EM) algorithm is a common approach for this, though gradient descent methods can also be used. Open-source tools, such as pyBKT, make it easy to train BKT models on real student data \citep{pardosOATutorOpensourceAdaptive2023, abdelrahmanKnowledgeTracingSurvey2023a}.

Beyond traditional BKT, \textbf{Deep Knowledge Tracing (DKT)} has emerged as a more powerful approach to knowledge tracing \citep{Piech2015DeepKT}. DKT uses recurrent neural networks to model student learning from sequences of interactions. Unlike BKT, it can capture complex patterns in student behavior and consider dependencies between skills automatically. Recent research further enhances DKT with memory, attention mechanisms, graph-based learning, textual features, and forgetting factors, improving both prediction accuracy and personalized guidance \citep{abdelrahmanKnowledgeTracingSurvey2023a}.

\section{The Need for a Research Platform}

Systematic experimentation is essential for rigorously evaluating instructional strategies within Intelligent Tutoring Systems (ITS). This requires a platform that natively supports flexible experimental designs, such as A/B testing, enabling structured comparisons of teaching methods. The system must collect rich, detailed data on student interactions, including hints and scaffold requests, rather than relying solely on correct or incorrect answers \citep{pardosOATutorOpensourceAdaptive2023}. Such data is crucial for validating instructional interventions, resolving the “assistance dilemma” of when to provide help, and ensuring system effectiveness is grounded in empirical evidence.

Despite these benefits, a gap remains in the field for ITS designed for systematic experimentation. Most existing systems lack this functionality, making controlled studies on different learning strategies difficult. The scarcity of open-source platforms further limits replication and raises the barrier for researchers. In addition, many ITS employ simplified learning models that collect limited interaction data, overlooking valuable insights and restricting the ability to test teaching strategies effectively \citep{pardosOATutorOpensourceAdaptive2023}.

Some existing tools, such as OATutor and ASSISTments, address this gap partially. OATutor is open-source but still relatively new. Platforms like ASSISTments often do not release their full codebase or content, limiting comprehensive experimentation and replication \citep{pardosOATutorOpensourceAdaptive2023, fengImplementingEvaluatingASSISTments2023}. This highlights the need for a platform that can handle complex subjects like Object-Oriented Programming while being built as a flexible research tool to support systematic experimentation and detailed data collection.

\section{Imerging Trends in Adaptive Learning}

\cite{liBringingGenerativeAI2024} examines the intersection of generative AI(GenAI) and Adaptive Learning(AI) in education. Given GenAI's recent rapid development, it presents a significant opportunity to integrate it into adaptive learning systems. GenAI can enhance different parts of an adaptive learning system, namely the learner module, instructional module, and content module. The paper highlights how GenAI can enhance profile building and content creation. It can also enhance tutoring by generating personalized questions, explanations, and study plans. Moreover, GenAI can provide real-time feedback and personalized guidance, much like a dialogue-based ITS \citep{Graesser2004AutoTutorAT}. However, AI hallucination, bias, and privacy remain key areas of concern. 

A study by \cite{wangExaminingApplicationsIntelligent2023} has found that ITS research and applications are heavily skewed towards developed countries like the USA. This geographical concentration mirrors national AI investment levels. This highlights the challenge of ensuring the ITS study and its benefits are shared equally worldwide. So, it becomes necessary to expand the creation and evaluation of ITS to a more diverse range of countries and educational settings.

